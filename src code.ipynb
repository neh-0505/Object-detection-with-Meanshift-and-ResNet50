{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanshift Tracking is a object tracking algorithm which works by iteratively shifting a window (or kernel) over the video data in such a way that it converges to the regions of maximum density or intensity. initially setup ROI calculating image histograms. and itirate the algorithm on ROI and track the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('highway_cars.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret, first_frame = cap.read()\n",
    "\n",
    "# setup initial location of window\n",
    "# creating rectangular box for the object of interest\n",
    "x =300\n",
    "y = 200\n",
    "h = 50\n",
    "w = 80\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = first_frame[x: x+h, y: y+w]\n",
    "hsv_roi =  cv2.cvtColor(first_frame, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_criteria = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    _, track_window = cv2.meanShift(mask, track_window, term_criteria)\n",
    "    \n",
    "    # draw on the image\n",
    "    x, y, w, h = track_window\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), 255, 2)\n",
    "\n",
    "    cv2.imshow(\"mask [esc to quit]\", mask)\n",
    "\n",
    "    cv2.imshow(\"frame [esc to quit]\", frame)\n",
    "\n",
    "    key = cv2.waitKey(60)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernelized Correlation Filter -tracking is another popular algorithm for object tracking. The ROI are used to train a correlation filter in the frequency domain. This filter represents the appearance of the target object.  In subsequent frames, the tracker uses the trained filter to detect the target object by applying correlation operations between the filter and the image patches in the vicinity of the last known location of the target.To adapt to changes in appearance due to variations in lighting, scale, or rotation, the correlation filter is continuously updated using newly observed image patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "x =300\n",
    "y = 200\n",
    "h = 50\n",
    "w = 80\n",
    "track_window = (x, y, w, h)\n",
    "bbox = (x, y, w, h)  # bounding box is a tuple of (x,y,w,h)\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "\n",
    "video = cv2.VideoCapture(\"highway_cars.mp4\")\n",
    "\n",
    "ok, frame = video.read()\n",
    "ok = tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break \n",
    "\n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "    else :\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    key = cv2.waitKey(60)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "    # # Exit if ESC key is pressed\n",
    "    # if cv2.waitKey(1) & 0xFF == 27:\n",
    "    #     break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resnet50 with Pytorch  -tracking ResNet-50 is a deep convolutional neural network architecture that has been widely used for object  detection  and tracking. initially Using  pre-trained ResNet-50 model to extract deep features and Utilize the extracted features as an appearance model for the target object. In subsequent frames, uses  techniques such as correlation filtering, template matching, or deep feature matching to locate the ROI and track it.  Periodically update the tracker using new image patches around the tracked object to account for changes in appearance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Initialize tracker with first frame and bounding box\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "video = cv2.VideoCapture(\"highway_cars.mp4\")\n",
    "\n",
    "ok, frame = video.read()\n",
    "# select ROI\n",
    "bbox = cv2.selectROI(frame, False) \n",
    "ok = tracker.init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ok, frame = video.read()\n",
    "    if not ok:\n",
    "        break \n",
    "\n",
    "    # Update tracker\n",
    "    ok, bbox = tracker.update(frame)\n",
    "\n",
    "    # Draw bounding box\n",
    "    if ok:\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "    else :\n",
    "        cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    key = cv2.waitKey(60)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
